name: "Compare Benchmarks"

on:
  workflow_dispatch:
    inputs:
      base_rev:
        description: "Base OpenVM revision to compare (defaults to latest main)"
        required: false
        type: string
      target_rev:
        description: "Target OpenVM revision to compare"
        required: true
        type: string
      benchmark_mode:
        type: choice
        required: false
        description: Running mode
        options:
          - execute
          - tracegen
          - prove-app
          - prove-stark
          - prove-evm
        default: prove-evm
      host_flamegraph:
        description: "Run target profiling benchmark for host flamegraph"
        type: boolean
        required: false
        default: false
      guest_flamegraph:
        description: "Run target profiling benchmark for circuit flamegraphs"
        type: boolean
        required: false
        default: false
      instance_family:
        description: "Instance family to use for benchmark"
        type: string
        required: false
        default: m8g.24xlarge

jobs:
  run-base-benchmark:
    name: "Run Base Benchmark"
    uses: ./.github/workflows/update-patches.yml
    with:
      OPENVM_REV: ${{ github.event.inputs.base_rev }}
      run_benchmark: true
      benchmark_mode: ${{ github.event.inputs.benchmark_mode }}
      instance_family: ${{ github.event.inputs.instance_family }}
    secrets: inherit

  # Only create branch because github workflow_call must run all jobs for "needs"
  patch-target:
    name: "Patch Target"
    uses: ./.github/workflows/update-patches.yml
    with:
      OPENVM_REV: ${{ github.event.inputs.target_rev }}
      run_benchmark: false
    secrets: inherit

  run-target-benchmark:
    name: "Run Target Benchmark"
    uses: ./.github/workflows/reth-benchmark.yml
    needs: patch-target
    with:
      mode: ${{ github.event.inputs.benchmark_mode }}
      instance_family: ${{ github.event.inputs.instance_family }}
      ref: ${{ needs.patch-target.outputs.branch_name }}
      tag: ${{ needs.patch-target.outputs.tag }}
      profiling: none
    secrets: inherit

  target-host-flamegraph:
    name: "Target Host Perf Flamegraph"
    uses: ./.github/workflows/reth-benchmark.yml
    if: ${{ github.event.inputs.host_flamegraph == 'true' }}
    needs: patch-target
    with:
      mode: ${{ github.event.inputs.benchmark_mode }}
      instance_family: ${{ github.event.inputs.instance_family }}
      ref: ${{ needs.patch-target.outputs.branch_name }}
      tag: ${{ needs.patch-target.outputs.tag }}
      profiling: host
    secrets: inherit

  target-guest-flamegraph:
    name: "Target Guest Circuit Flamegraphs"
    uses: ./.github/workflows/reth-benchmark.yml
    if: ${{ github.event.inputs.guest_flamegraph == 'true' }}
    needs: patch-target
    with:
      mode: ${{ github.event.inputs.benchmark_mode }}
      instance_family: ${{ github.event.inputs.instance_family }}
      ref: ${{ needs.patch-target.outputs.branch_name }}
      tag: ${{ needs.patch-target.outputs.tag }}
      profiling: guest
    secrets: inherit

  compare-results:
    needs:
      - run-base-benchmark
      - run-target-benchmark
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Download base benchmark results
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.run-base-benchmark.outputs.metric_name }}
          path: ${{ needs.run-base-benchmark.outputs.metric_name }}

      - name: Download target benchmark results
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.run-target-benchmark.outputs.metric_name }}
          path: ${{ needs.run-target-benchmark.outputs.metric_name }}

      - name: Install openvm-prof
        run: |
          cargo install --git https://github.com/powdr-labs/openvm.git --rev 33abb41 --profile=dev --force openvm-prof
      - name: Compare metrics
        run: |
          ls
          BASE_NAME=${{ needs.run-base-benchmark.outputs.metric_name }}
          BASE_JSON=$BASE_NAME/metrics.json
          TARGET_NAME=${{ needs.run-target-benchmark.outputs.metric_name }}
          TARGET_JSON=$TARGET_NAME/metrics.json

          openvm-prof --json-paths $TARGET_JSON --prev-json-paths $BASE_JSON
          MD_PATH=${TARGET_JSON%.json}.md
          # Inspired by https://github.com/rustls/rustls/blob/7159373401f253cbaacd276634508e0798a8849f/.github/workflows/icount-bench.yml#L37
          cat $MD_PATH >> $GITHUB_STEP_SUMMARY

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Workflow Inputs" >> $GITHUB_STEP_SUMMARY
          echo "Base OpenVM Revision: ${{ github.event.inputs.base_rev }}" >> $GITHUB_STEP_SUMMARY
          echo "Target OpenVM Revision: ${{ github.event.inputs.target_rev }}" >> $GITHUB_STEP_SUMMARY
          echo "Instance Family: ${{ github.event.inputs.instance_family }}" >> $GITHUB_STEP_SUMMARY
          echo "Benchmark Mode: ${{ github.event.inputs.benchmark_mode }}" >> $GITHUB_STEP_SUMMARY
